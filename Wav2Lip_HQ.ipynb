{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkoF-mm8CGfB"
      },
      "source": [
        "# Wav2Lip-HQ inference\n",
        "\n",
        "This notebook is a demo describing Wav2Lip-HQ model for lip-sync of high quality videos.\n",
        "\n",
        "* Github: https://github.com/Markfryazino/wav2lip-hq\n",
        "* Paper: https://arxiv.org/abs/2008.10010\n",
        "* Original notebook: https://colab.research.google.com/drive/1bwgV-31JLNFTKCVDnJtTbP4brOUV1xaL?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uJWURePONLd"
      },
      "source": [
        "## At first, clone the repository and load all required models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Lb6Q78lTNeSj"
      },
      "outputs": [],
      "source": [
        "#@title <h1>Step1: Setup Wav2Lip</h1>\n",
        "#@markdown * Install dependency\n",
        "#@markdown * Download pretrained model\n",
        "from IPython.display import clear_output\n",
        "import os, urllib.request\n",
        "HOME = os.path.expanduser(\"~\")\n",
        "pathDoneCMD = f'{HOME}/doneCMD.sh'\n",
        "if not os.path.exists(f\"{HOME}/.ipython/ttmg.py\"):\n",
        "    hCode = \"https://raw.githubusercontent.com/sudo-ken/FFmpeg-for-GDrive/master/ttmg.py\"\n",
        "    urllib.request.urlretrieve(hCode, f\"{HOME}/.ipython/ttmg.py\")\n",
        " \n",
        "from ttmg import (\n",
        "    loadingAn,\n",
        "    textAn,\n",
        ")\n",
        " \n",
        "loadingAn(name=\"lds\")\n",
        "textAn(\"Installing Dependencies...\", ty='twg')\n",
        "\n",
        "os.system('git clone https://github.com/Markfryazino/wav2lip-hq.git')\n",
        "%cd wav2lip-hq\n",
        "os.system('pip3 install gdown')\n",
        "os.system('pip3 install -r requirements.txt')\n",
        "os.system('pip install -q youtube-dl')\n",
        "os.system('pip install ffmpeg-python')\n",
        "os.system('pip install https://raw.githubusercontent.com/AwaleSajil/ghc/master/ghc-1.0-py3-none-any.whl')\n",
        "\n",
        "os.system('wget \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" -O \"face_detection/detection/sfd/s3fd.pth\"')\n",
        "\n",
        "import gdown\n",
        "\n",
        "urls = {\n",
        "    \"wav2lip_gan.pth\": \"10Iu05Modfti3pDbxCFPnofmfVlbkvrCm\", \n",
        "    \"face_segmentation.pth\": \"154JgKpzCPW82qINcVieuPH3fZ2e0P812\",\n",
        "    \"esrgan_max.pth\": \"1e5LT83YckB5wFKXWV4cWOPkVRnCDmvwQ\",\n",
        "    \"esrgan_yunying.pth\": \"1aB-jqBikcZPJnFrJXWUEpvF2RFCuerSe\",\n",
        "    \"pretrained.state\": \"1_MGeOLdARWHylC1PCU2p5_FQztD4Bo7B\"\n",
        "}\n",
        "\n",
        "for name, id in urls.items():\n",
        "    url = f\"https://drive.google.com/uc?id={id}\"\n",
        "    output = f\"checkpoints/{name}\"\n",
        "    gdown.download(url, output, quiet=False)\n",
        "    print(f\"Loaded {name}\")\n",
        "\n",
        "#this code for recording audio\n",
        "\"\"\"\n",
        "To write this piece of code I took inspiration/code from a lot of places.\n",
        "It was late night, so I'm not sure how much I created or just copied o.O\n",
        "Here are some of the possible references:\n",
        "https://blog.addpipe.com/recording-audio-in-the-browser-using-pure-html5-and-minimal-javascript/\n",
        "https://stackoverflow.com/a/18650249\n",
        "https://hacks.mozilla.org/2014/06/easy-audio-capture-with-the-mediarecorder-api/\n",
        "https://air.ghost.io/recording-to-an-audio-file-using-html5-and-js/\n",
        "https://stackoverflow.com/a/49019356\n",
        "\"\"\"\n",
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };            \n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {            \n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data); \n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      //console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
        "  }\n",
        "}\n",
        "\n",
        "// https://stackoverflow.com/a/951057\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "//recordButton.addEventListener(\"click\", toggleRecording);\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "\n",
        "sleep(2000).then(() => {\n",
        "  // wait 2000ms for the data to be available...\n",
        "  // ideally this should use something like await...\n",
        "  //console.log(\"Inside data:\" + base64data)\n",
        "  resolve(base64data.toString())\n",
        "\n",
        "});\n",
        "\n",
        "}\n",
        "});\n",
        "      \n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "%cd /\n",
        "from ghc.l_ghc_cf import l_ghc_cf\n",
        "%cd content\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  \n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "  \n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  return audio, sr\n",
        "\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "def showVideo(path):\n",
        "  mp4 = open(str(path),'rb').read()\n",
        "  data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "  return HTML(\"\"\"\n",
        "  <video width=700 controls>\n",
        "        <source src=\"%s\" type=\"video/mp4\">\n",
        "  </video>\n",
        "  \"\"\" % data_url)\n",
        "\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUyqAPGwRcGj"
      },
      "source": [
        "## Now upload target audio and video.\n",
        "\n",
        "You can just upload via Google Colab interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YkSRYUV-RTF9"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color=\"red\"> (DO NOT RUN)\n",
        "#@markdown <b><font color=\"red\"> ONLY FOR TESTING\n",
        "# If you load files from Drive, run this cell\n",
        "\n",
        "# Paste your filenames and Google Drive IDs below.\n",
        "urls = {\n",
        "    \"shulman_30s.mp4\": \"1bkvqn_tW6lDDjCLatPkT7XlXm9zFDdQl\",\n",
        "    \"yunying_30s.mp4\": \"1dggydm07RHrxiFUIH_51RXmkMcD_bMPE\",\n",
        "}\n",
        "\n",
        "for name, id in urls.items():\n",
        "    url = f\"https://drive.google.com/uc?id={id}\"\n",
        "    output = f\"videos/{name}\"\n",
        "    gdown.download(url, output, quiet=False)\n",
        "    print(f\"Loaded {name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ktaLsPP6Txbn"
      },
      "outputs": [],
      "source": [
        "#@title STEP2: Select a Youtube Video\n",
        "video_url = 'https://youtu.be/nL8hVXSDmNM' #@param {type:\"string\"}\n",
        "\n",
        "import shutil\n",
        "\n",
        "import os\n",
        "import os.path\n",
        "from IPython.display import clear_output\n",
        "import youtube_dl\n",
        "\n",
        "loadingAn(name=\"lds\")\n",
        "textAn(\"Downloading Video...\", ty='twg')\n",
        "if video_url:\n",
        "  !rm -f /content/wav2lip-hq/videos/youtube.mp4\n",
        "  !youtube-dl -f \"bestvideo[ext=mp4][vcodec!*=av01][height<=360]+bestaudio[ext=m4a]/mp4[height<=360][vcodec!*=av01]/mp4[vcodec!*=av01]/mp4\" \"$video_url\" --merge-output-format mp4 -o /content/wav2lip-hq/videos/youtube.mp4\n",
        "\n",
        "# cut the video\n",
        "textAn(\"Trimming Video...\", ty='twg')\n",
        "\n",
        "start_seconds = 15 #@param {type:\"number\"}\n",
        "duration_seconds =  42#@param {type:\"number\"}\n",
        "start_seconds = max(start_seconds,0)\n",
        "duration_seconds = max(duration_seconds,0)\n",
        "\n",
        "if duration_seconds:\n",
        "  !mv /content/wav2lip-hq/videos/youtube.mp4 /content/full_video.mp4\n",
        "  !ffmpeg -ss $start_seconds -t $duration_seconds -i /content/full_video.mp4 -f mp4 /content/wav2lip-hq/videos/youtube.mp4 -y\n",
        "\n",
        "!rm -df youtube.mp4\n",
        "# download the youtube with the given ID\n",
        "\n",
        "#delete video.mp4 if already exits\n",
        "!rm -f /content/wav2lip-hq/videos/ass.mp4\n",
        "\n",
        "\n",
        "#Preview trimmed video\n",
        "clear_output()\n",
        "print(\"Trimmed Video\")\n",
        "showVideo('/content/wav2lip-hq/videos/youtube.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cWQhUrIrfc9r"
      },
      "outputs": [],
      "source": [
        "#@title STEP3: Select Audio (Record or Upload)\n",
        "from IPython.display import Audio \n",
        "from IPython.core.display import display\n",
        "import shutil\n",
        "import os, sys, re\n",
        "record_or_upload = 'Upload' #@param ['Record', 'Upload']\n",
        "\n",
        "def displayAudio():\n",
        "  display(Audio('/content/wav2lip-hq/videos/input_audioconverted.wav'))\n",
        "if record_or_upload == 'Record':\n",
        "  audio, sr = get_audio()\n",
        "  import scipy\n",
        "  scipy.io.wavfile.write('/content/wav2lip-hq/videos/input_audioaudioconverted.wav', sr, audio)\n",
        "  clear_output()\n",
        "  displayAudio()\n",
        "  # stop\n",
        "  print(\"Ignore the error it will be fix soon.\")\n",
        "  !sudo mpirun --allow-run-as-root -n lmp_stable -sf gpu -pk gpu 1 neigh no newton off -in LAMMPS_inp\n",
        "elif record_or_upload == 'Upload':\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()\n",
        "  dst ='input_audio.mp3' \n",
        "  os.rename(list(uploaded.keys())[0], dst)\n",
        "  for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))\n",
        "    shutil.move(\"/content/input_audio.mp3\", \"/content/wav2lip-hq/videos\")\n",
        "\n",
        "loadingAn(name=\"lds\")\n",
        "textAn(\"Converting Audio...\", ty='twg')\n",
        "\n",
        "audio_file_path = \"/content/wav2lip-hq/videos/input_audio.mp3\"\n",
        "output_file_type = \"wav\"\n",
        "\n",
        "output_file_path = re.search(\"^[\\/].+\\/\", audio_file_path)\n",
        "output_file_path_raw = output_file_path.group(0)\n",
        "delsplit = re.search(\"\\/(?:.(?!\\/))+$\", audio_file_path)\n",
        "filename = re.sub(\"^[\\/]\", \"\", delsplit.group(0))\n",
        "filename_raw = re.sub(\".{4}$\", \"\", filename)\n",
        "file_extension = re.search(\".{3}$\", filename)\n",
        "file_extension_raw = file_extension.group(0)\n",
        "\n",
        "os.environ['inputFile'] = audio_file_path\n",
        "os.environ['outputPath'] = output_file_path_raw\n",
        "os.environ['fileExtension'] = output_file_type\n",
        "os.environ['fileName'] = filename_raw\n",
        "\n",
        "os.system('ffmpeg -hide_banner -i \"$inputFile\" \"$outputPath\"/\"$fileName\"converted.\"$fileExtension\"')\n",
        "\n",
        "#concider only the first file\n",
        "audio_file = str(list(uploaded.keys())[0])\n",
        "!rm -f '/content/wav2lip-hq/videos/input_audio.mp3'\n",
        "!ffmpeg -i '$audio_file' '/content/wav2lip-hq/videos/input_audioconverted.wav'\n",
        "\n",
        "input_audio = \"/content/wav2lip-hq/videos/input_audioconverted.wav\"\n",
        "\n",
        "s = 1\n",
        "\n",
        "if s == 1:\n",
        "  display(Audio(input_audio, autoplay=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VkUrDibgroKX"
      },
      "outputs": [],
      "source": [
        "#@title Delete old input audio file\n",
        "%rm /content/wav2lip-hq/videos/input_audioconverted.wav\n",
        "from IPython.display import clear_output \n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FdYMpGXFWNJN"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color=\"red\"> (DO NOT RUN)\n",
        "#@markdown <b><font color=\"red\"> ONLY FOR TESTING\n",
        "from IPython.display import Audio, display\n",
        "from IPython.core.display import display\n",
        "import time\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "record_or_upload = 'Record' #@param ['Record', 'Upload']\n",
        "\n",
        "SAMPLE_RATE = 44100\n",
        "record_seconds = 10#@param {type:\"number\"}\n",
        "\n",
        "stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "recorder = new MediaRecorder(stream)\n",
        "chunks = []\n",
        "recorder.ondataavailable = e => chunks.push(e.data)\n",
        "\n",
        "if record_or_upload == 'Upload':\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()\n",
        "  dst ='input_audio.mp3' \n",
        "  os.rename(list(uploaded.keys())[0], dst)\n",
        "  for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))\n",
        "#concider only the this file\n",
        "shutil.move(\"/content/input_audio.mp3\", \"/content/wav2lip-hq/videos\")\n",
        "\n",
        "loadingAn(name=\"lds\")\n",
        "textAn(\"Converting Audio...\", ty='twg')\n",
        "\n",
        "audio_file_path = \"/content/wav2lip-hq/videos/input_audio.mp3\"\n",
        "output_file_type = \"wav\"\n",
        "\n",
        "output_file_path = re.search(\"^[\\/].+\\/\", audio_file_path)\n",
        "output_file_path_raw = output_file_path.group(0)\n",
        "delsplit = re.search(\"\\/(?:.(?!\\/))+$\", audio_file_path)\n",
        "filename = re.sub(\"^[\\/]\", \"\", delsplit.group(0))\n",
        "filename_raw = re.sub(\".{4}$\", \"\", filename)\n",
        "file_extension = re.search(\".{3}$\", filename)\n",
        "file_extension_raw = file_extension.group(0)\n",
        "\n",
        "os.environ['inputFile'] = audio_file_path\n",
        "os.environ['outputPath'] = output_file_path_raw\n",
        "os.environ['fileExtension'] = output_file_type\n",
        "os.environ['fileName'] = filename_raw\n",
        "\n",
        "os.system('ffmpeg -hide_banner -i \"$inputFile\" \"$outputPath\"/\"$fileName\"converted.\"$fileExtension\"')\n",
        "\n",
        "#concider only the first file\n",
        "audio_file = str(list(uploaded.keys())[0])\n",
        "!rm -f '/content/wav2lip-hq/videos/input_audio.wav'\n",
        "!ffmpeg -i '$audio_file' '/content/wav2lip-hq/videos/input_audio.wav'\n",
        "\n",
        "input_audio = \"/content/wav2lip-hq/videos/input_audioconverted.wav\"\n",
        "\n",
        "s = 1\n",
        "\n",
        "if s == 1:\n",
        "  display(Audio(input_audio, autoplay=True))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9WRj2KBVojD"
      },
      "source": [
        "## Finally, run the model!\n",
        "\n",
        "Also, you may want to change `--sr-path` if you've pretrained the super resolution model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "upzbvGOmVnJT"
      },
      "outputs": [],
      "source": [
        "#@title <b><font color=\"red\"> (DO NOT RUN)\n",
        "#@markdown <b><font color=\"red\"> ONLY FOR TESTING\n",
        "!python inference.py \\\n",
        "        --checkpoint_path \"checkpoints/wav2lip_gan.pth\" \\\n",
        "        --segmentation_path \"checkpoints/face_segmentation.pth\" \\\n",
        "        --sr_path \"checkpoints/esrgan_max.pth\" \\\n",
        "        --face \"videos/yunying_30s.mp4\" \\\n",
        "        --audio \"videos/shulman_30s.mp4\" \\\n",
        "        --outfile \"results/shulman_to_yunying.mp4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fJ9O8rwcTdQg"
      },
      "outputs": [],
      "source": [
        "#@title STEP4: Start Crunching and Preview Output\n",
        "#@markdown <b>Note: Only change these, if you have to</b>\n",
        "pad_top =  0#@param {type:\"integer\"}\n",
        "pad_bottom =  10#@param {type:\"integer\"}\n",
        "pad_left =  0#@param {type:\"integer\"}\n",
        "pad_right =  0#@param {type:\"integer\"}\n",
        "rescaleFactor =  1#@param {type:\"integer\"}\n",
        "sr_path = 'checkpoints/esrgan_max.pth' #@param {type:\"string\"}\n",
        "nosmooth = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "loadingAn(name=\"lds\")\n",
        "textAn(\"Analyzing Video...\", ty='twg')\n",
        "\n",
        "if nosmooth == False:\n",
        "  !cd wav2lip-hq && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --segmentation_path checkpoints/face_segmentation.pth --sr_path checkpoints/esrgan_max.pth --face \"/content/wav2lip-hq/videos/youtube.mp4\" --audio \"/content/wav2lip-hq/videos/input_audioconverted.wav\" --pads $pad_top $pad_bottom $pad_left $pad_right --resize_factor $rescaleFactor\n",
        "else:\n",
        "  !cd wav2lip-hq && pyt hon inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --segmentation_path checkpoints/face_segmentation.pth --sr_path --face \"/content/wav2lip-hq/videos/youtube.mp4\" --audio \"/content/wav2lip-hq/videos/input_audioconverted.wav\" --pads $pad_top $pad_bottom $pad_left $pad_right --resize_factor $rescaleFactor --nosmooth\n",
        "\n",
        "#Preview output video\n",
        "clear_output()\n",
        "print(\"Final Video Preview\")\n",
        "print(\"Dowload this video from\", '/content/wav2lip-hq/results/result_voice.mp4')\n",
        "showVideo('/content/wav2lip-hq/results/result_voice.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "x0zA3eG97rDJ"
      },
      "outputs": [],
      "source": [
        "#@title You might get better results by running this cell\n",
        "pad_top =  0#@param {type:\"integer\"}\n",
        "pad_bottom =  10#@param {type:\"integer\"}\n",
        "pad_left =  0#@param {type:\"integer\"}\n",
        "pad_right =  0#@param {type:\"integer\"}\n",
        "rescaleFactor =  1#@param {type:\"integer\"}\n",
        "\n",
        "loadingAn(name=\"lds\")\n",
        "textAn(\"Analyzing Video...\", ty='twg')\n",
        "\n",
        "!cd wav2lip-hq && python inference.py --checkpoint_path \"checkpoints/wav2lip_gan.pth\"  --segmentation_path \"checkpoints/face_segmentation.pth\"  --sr_path \"checkpoints/esrgan_yunying.pth\" --face \"/content/wav2lip-hq/videos/youtube.mp4\"  --audio \"/content/wav2lip-hq/videos/input_audioconverted.wav\"  --save_frames  --gt_path \"data/gt\"  --pred_path \"data/lq\"  --no_sr --no_segmentation --pads $pad_top $pad_bottom $pad_left $pad_right --resize_factor $rescaleFactor\n",
        "\n",
        "#Preview output video\n",
        "clear_output()\n",
        "print(\"Final Video Preview\")\n",
        "print(\"Dowload this video from\", '/content/wav2lip-hq/results/result_voice.mp4')\n",
        "showVideo('/content/wav2lip-hq/results/result_voice.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "K8OOq0G64Ofn"
      },
      "outputs": [],
      "source": [
        "#@title Download Video\n",
        "#@markdown 1. If it fails try running this cell again.\n",
        "#@markdown 2. Alternatively, you can manually download \"output.mp4\", \"combined.mp4\" from the folder on the left (click \"Refresh\" if missing).\n",
        "\n",
        "print() #see https://github.com/googlecolab/colabtools/issues/468\n",
        "from google.colab import files\n",
        "files.download('/content/wav2lip-hq/results/result_voice.mp4') #fails for Firefox private window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GMbkBYP9slDI"
      },
      "outputs": [],
      "source": [
        "#@title Delete old result file\n",
        "%rm /content/wav2lip-hq/results/result_voice.mp4\n",
        "from IPython.display import clear_output \n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ30PqUytLSF"
      },
      "source": [
        "# LipSync on Your Video File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "mivLpPPTryz6",
        "outputId": "9f107be1-d440-4777-ab6a-49c74ea2dbf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Video\n"
          ]
        }
      ],
      "source": [
        "#@title STEP2: Upload your Video File\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "dst ='input_vid.mp4' \n",
        "os.rename(list(uploaded.keys())[0], dst)\n",
        "\n",
        "loadingAn(name=\"lds\")\n",
        "textAn(\"Moving Video...\", ty='twg')\n",
        "\n",
        "PATH_TO_YOU_VIDEO = '/content/input_vid.mp4'\n",
        "import os, sys, re\n",
        "import subprocess\n",
        "\n",
        "shutil.move(\"/content/input_vid.mp4\", \"/content/wav2lip-hq/videos\") \n",
        "\n",
        "#@markdown ### Trim the video (start, end) seconds\n",
        "#@markdown <i>Don't want to trim ? put <b>'start'</b> = -1 and <b>'end'</b> = -1</i>\n",
        "start =  -1#@param {type:\"integer\"}\n",
        "end =  -1#@param {type:\"integer\"}\n",
        "\n",
        "\n",
        "#@markdown <i>Note: the trimmed video must have face on all frames</i>\n",
        "\n",
        "# delete start end\n",
        "interval = end - start\n",
        "\n",
        "textAn(\"Triming Video...\", ty='twg')\n",
        "\n",
        "#delete if file already exists\n",
        "!rm -f '/content/input.vid.mp4'\n",
        "\n",
        "if start < 0 or end < 0:\n",
        "  #convert the video to specif location\n",
        "  !ffmpeg -i '$PATH_TO_YOU_VIDEO' '/content/wav2lip-hq/videos/input_vid.mp4'\n",
        "else:\n",
        "  # cut the video\n",
        "  !ffmpeg -i '$PATH_TO_YOU_VIDEO' -ss {start} -t {interval} -async 1 '/content/wav2lip-hq/videos/input_vid.mp4'\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Preview trimmed video\n",
        "clear_output()\n",
        "print(\"Input Video\")\n",
        "showVideo('/content/wav2lip-hq/videos/input_vid.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4P2YbxQzB4X9"
      },
      "outputs": [],
      "source": [
        "#@title Delete old input Video file\n",
        "%rm /content/wav2lip-hq/videos/input_vid.mp4\n",
        "from IPython.display import clear_output \n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eoT1YMZo2ikc"
      },
      "outputs": [],
      "source": [
        "#@title STEP3: Select Audio (Record or Upload)\n",
        "from IPython.display import Audio \n",
        "from IPython.core.display import display\n",
        "import shutil\n",
        "import os, sys, re\n",
        "record_or_upload = 'Upload' #@param ['Record', 'Upload']\n",
        "\n",
        "def displayAudio():\n",
        "  display(Audio('/content/wav2lip-hq/videos/input_audio_sec.wav'))\n",
        "if record_or_upload == 'Record':\n",
        "  audio, sr = get_audio()\n",
        "  import scipy\n",
        "  scipy.io.wavfile.write('/content/wav2lip-hq/videos/input_audio_sec.wav', sr, audio)\n",
        "  clear_output()\n",
        "  displayAudio()\n",
        "  # stop\n",
        "  print(\"Ignore the error it will be fix soon.\")\n",
        "  !sudo mpirun --allow-run-as-root -n lmp_stable -sf gpu -pk gpu 1 neigh no newton off -in LAMMPS_inp\n",
        "elif record_or_upload == 'Upload':\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()\n",
        "  dst ='input_audio_sec.mp3' \n",
        "  os.rename(list(uploaded.keys())[0], dst)\n",
        "  for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))\n",
        "    shutil.move(\"/content/input_audio_sec.mp3\", \"/content/wav2lip-hq/videos\")\n",
        "\n",
        "loadingAn(name=\"lds\")\n",
        "textAn(\"Converting Audio...\", ty='twg')\n",
        "\n",
        "audio_file_path = \"/content/wav2lip-hq/videos/input_audio_sec.mp3\"\n",
        "output_file_type = \"wav\"\n",
        "\n",
        "output_file_path = re.search(\"^[\\/].+\\/\", audio_file_path)\n",
        "output_file_path_raw = output_file_path.group(0)\n",
        "delsplit = re.search(\"\\/(?:.(?!\\/))+$\", audio_file_path)\n",
        "filename = re.sub(\"^[\\/]\", \"\", delsplit.group(0))\n",
        "filename_raw = re.sub(\".{4}$\", \"\", filename)\n",
        "file_extension = re.search(\".{3}$\", filename)\n",
        "file_extension_raw = file_extension.group(0)\n",
        "\n",
        "os.environ['inputFile'] = audio_file_path\n",
        "os.environ['outputPath'] = output_file_path_raw\n",
        "os.environ['fileExtension'] = output_file_type\n",
        "os.environ['fileName'] = filename_raw\n",
        "\n",
        "os.system('ffmpeg -hide_banner -i \"$inputFile\" \"$outputPath\"/\"$fileName\"convert.\"$fileExtension\"')\n",
        "\n",
        "#concider only the first file\n",
        "audio_file = str(list(uploaded.keys())[0])\n",
        "!rm -f '/content/wav2lip-hq/videos/input_audio_sec.mp3'\n",
        "!ffmpeg -i '$audio_file' '/content/wav2lip-hq/videos/input_audioconvert.wav'\n",
        "\n",
        "input_audio = \"/content/wav2lip-hq/videos/input_audioconvert.wav\"\n",
        "\n",
        "s = 1\n",
        "\n",
        "if s == 1:\n",
        "  display(Audio(input_audio, autoplay=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6G6Ehrvwwdg1"
      },
      "outputs": [],
      "source": [
        "#@title Delete old input audio file\n",
        "%rm /content/wav2lip-hq/videos/input_audioconvert.wav\n",
        "from IPython.display import clear_output \n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "B9-regvd2o7w"
      },
      "outputs": [],
      "source": [
        "#@title STEP4: Start Crunching and Preview Output\n",
        "#@markdown <b>Note: Only change these, if you have to</b>\n",
        "pad_top =  0#@param {type:\"integer\"}\n",
        "pad_bottom =  10#@param {type:\"integer\"}\n",
        "pad_left =  0#@param {type:\"integer\"}\n",
        "pad_right =  0#@param {type:\"integer\"}\n",
        "rescaleFactor =  1#@param {type:\"integer\"}\n",
        "sr_path = 'checkpoints/esrgan_max.pth' #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "loadingAn(name=\"lds\")\n",
        "textAn(\"Analyzing Video...\", ty='twg')\n",
        "\n",
        "if nosmooth == False:\n",
        "  !cd wav2lip-hq && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --segmentation_path checkpoints/face_segmentation.pth --sr_path checkpoints/esrgan_max.pth --face \"/content/wav2lip-hq/videos/input_vid.mp4\" --audio \"/content/wav2lip-hq/videos/input_audioconverted.wav\" --pads $pad_top $pad_bottom $pad_left $pad_right --resize_factor $rescaleFactor\n",
        "else:\n",
        "  !cd wav2lip-hq && pyt hon inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --segmentation_path checkpoints/face_segmentation.pth --sr_path --face \"/content/wav2lip-hq/videos/input_vid.mp4\" --audio \"/content/wav2lip-hq/videos/input_audioconverted.wav\" --pads $pad_top $pad_bottom $pad_left $pad_right --resize_factor $rescaleFactor --nosmooth\n",
        "\n",
        "#Preview output video\n",
        "clear_output()\n",
        "print(\"Final Video Preview\")\n",
        "print(\"Dowload this video from\", '/content/wav2lip-hq/results/result_voice.mp4')\n",
        "showVideo('/content/wav2lip-hq/results/result_voice.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IWARexZJAFnD"
      },
      "outputs": [],
      "source": [
        "#@title You might get better results by running this cell\n",
        "pad_top =  0#@param {type:\"integer\"}\n",
        "pad_bottom =  10#@param {type:\"integer\"}\n",
        "pad_left =  0#@param {type:\"integer\"}\n",
        "pad_right =  0#@param {type:\"integer\"}\n",
        "rescaleFactor =  1#@param {type:\"integer\"}\n",
        "\n",
        "loadingAn(name=\"lds\")\n",
        "textAn(\"Analyzing Video...\", ty='twg')\n",
        "\n",
        "!cd wav2lip-hq && python inference.py --checkpoint_path \"checkpoints/wav2lip_gan.pth\"  --segmentation_path \"checkpoints/face_segmentation.pth\"  --sr_path \"checkpoints/esrgan_yunying.pth\" --face \"/content/wav2lip-hq/videos/youtube.mp4\"  --audio \"/content/wav2lip-hq/videos/input_audioconverted.wav\"  --save_frames  --gt_path \"data/gt\"  --pred_path \"data/lq\"  --no_sr --no_segmentation --pads $pad_top $pad_bottom $pad_left $pad_right --resize_factor $rescaleFactor\n",
        "\n",
        "#Preview output video\n",
        "clear_output()\n",
        "print(\"Final Video Preview\")\n",
        "print(\"Dowload this video from\", '/content/wav2lip-hq/results/result_voice.mp4')\n",
        "showVideo('/content/wav2lip-hq/results/result_voice.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oVbGEkvN4DYi"
      },
      "outputs": [],
      "source": [
        "#@title Download Video\n",
        "#@markdown 1. If it fails try running this cell again.\n",
        "#@markdown 2. Alternatively, you can manually download \"output.mp4\", \"combined.mp4\" from the folder on the left (click \"Refresh\" if missing).\n",
        "\n",
        "print() #see https://github.com/googlecolab/colabtools/issues/468\n",
        "from google.colab import files\n",
        "files.download('/content/wav2lip-hq/results/result_voice.mp4') #fails for Firefox private window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7YDHAA8Ls8f_"
      },
      "outputs": [],
      "source": [
        "#@title Delete old result file\n",
        "%rm /content/wav2lip-hq/results/result_voice.mp4\n",
        "from IPython.display import clear_output \n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtXBKwdgCihr"
      },
      "source": [
        "# LipSync on Your Image File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "op0fg0FWCfuL"
      },
      "outputs": [],
      "source": [
        "#@title STEP2: Select a Image\n",
        "image_url = 'https://i.pinimg.com/564x/74/9e/96/749e96293399ebe1b8c99d89be522383.jpg' #@param {type:\"string\"}\n",
        "import shutil\n",
        "import cv2\n",
        "from IPython.display import Image\n",
        "\n",
        "if image_url:\n",
        "  !wget \"$image_url\" -O /content/wav2lip-hq/images/image.png\n",
        "\n",
        "Image('/content/wav2lip-hq/images/image.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OzkTdS2ktgAG"
      },
      "outputs": [],
      "source": [
        "#@title STEP2+: Upload your Image\n",
        "import os\n",
        "from google.colab import files\n",
        "import cv2\n",
        "import shutil\n",
        "from IPython.display import Image\n",
        "uploaded = files.upload()\n",
        "dst ='image.png' \n",
        "os.rename(list(uploaded.keys())[0], dst)\n",
        "shutil.move(\"/content/image.png\", \"/content/wav2lip-hq/images\")\n",
        "\n",
        "Image('/content/wav2lip-hq/images/image.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4GjtnfVO0hKK"
      },
      "outputs": [],
      "source": [
        "#@title Delete old input Image file\n",
        "%rm /content/wav2lip-hq/images/image.png\n",
        "from IPython.display import clear_output \n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_YmgCR6WzNdF"
      },
      "outputs": [],
      "source": [
        "#@title STEP3: Select Audio (Record or Upload)\n",
        "from IPython.display import Audio \n",
        "from IPython.core.display import display\n",
        "import shutil\n",
        "import os, sys, re\n",
        "record_or_upload = 'Upload' #@param ['Record', 'Upload']\n",
        "\n",
        "def displayAudio():\n",
        "  display(Audio('/content/wav2lip-hq/videos/input_audio_img.wav'))\n",
        "if record_or_upload == 'Record':\n",
        "  audio, sr = get_audio()\n",
        "  import scipy\n",
        "  scipy.io.wavfile.write('/content/wav2lip-hq/videos/input_audio_img.wav', sr, audio)\n",
        "  clear_output()\n",
        "  displayAudio()\n",
        "  # stop\n",
        "  print(\"Ignore the error it will be fix soon.\")\n",
        "  !sudo mpirun --allow-run-as-root -n lmp_stable -sf gpu -pk gpu 1 neigh no newton off -in LAMMPS_inp\n",
        "elif record_or_upload == 'Upload':\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()\n",
        "  dst ='input_audio_image.mp3' \n",
        "  os.rename(list(uploaded.keys())[0], dst)\n",
        "  for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))\n",
        "    shutil.move(\"/content/input_audio_image.mp3\", \"/content/wav2lip-hq/videos\")\n",
        "\n",
        "loadingAn(name=\"lds\")\n",
        "textAn(\"Converting Audio...\", ty='twg')\n",
        "\n",
        "audio_file_path = \"/content/wav2lip-hq/videos/input_audio_image.mp3\"\n",
        "output_file_type = \"wav\"\n",
        "\n",
        "output_file_path = re.search(\"^[\\/].+\\/\", audio_file_path)\n",
        "output_file_path_raw = output_file_path.group(0)\n",
        "delsplit = re.search(\"\\/(?:.(?!\\/))+$\", audio_file_path)\n",
        "filename = re.sub(\"^[\\/]\", \"\", delsplit.group(0))\n",
        "filename_raw = re.sub(\".{4}$\", \"\", filename)\n",
        "file_extension = re.search(\".{3}$\", filename)\n",
        "file_extension_raw = file_extension.group(0)\n",
        "\n",
        "os.environ['inputFile'] = audio_file_path\n",
        "os.environ['outputPath'] = output_file_path_raw\n",
        "os.environ['fileExtension'] = output_file_type\n",
        "os.environ['fileName'] = filename_raw\n",
        "\n",
        "os.system('ffmpeg -hide_banner -i \"$inputFile\" \"$outputPath\"/\"$fileName\"converting.\"$fileExtension\"')\n",
        "\n",
        "#concider only the first file\n",
        "audio_file = str(list(uploaded.keys())[0])\n",
        "!rm -f '/content/wav2lip-hq/videos/input_audio_image.mp3'\n",
        "!ffmpeg -i '$audio_file' '/content/wav2lip-hq/videos/input_audio_imageconverting.wav'\n",
        "\n",
        "input_audioconverting = \"/content/wav2lip-hq/videos/input_audio_imageconverting.wav\"\n",
        "\n",
        "s = 1\n",
        "\n",
        "if s == 1:\n",
        "  display(Audio(input_audioconverting, autoplay=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6Z8qluzM0MRd"
      },
      "outputs": [],
      "source": [
        "#@title Delete old input audio file\n",
        "%rm /content/wav2lip-hq/videos/input_audio_imageconverting.wav\n",
        "from IPython.display import clear_output \n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "U5_msoGb5Xvb"
      },
      "outputs": [],
      "source": [
        "#@title Optional: The snippet to resize ground truth images to 384  Ã—  384 resolution.\n",
        "import os\n",
        "\n",
        "paths = os.listdir(\"data/gt\")\n",
        "\n",
        "for img_path in tqdm(paths):\n",
        "    img = cv2.imread(\"data/gt/\" + img_path)\n",
        "    img = cv2.resize(img, (384, 384))\n",
        "    cv2.imwrite(\"data/hq/\" + img_path, img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "w9cgOrOa0xUR"
      },
      "outputs": [],
      "source": [
        "#@title STEP4: Start Crunching and Preview Output\n",
        "#@markdown <b>Note: Only change these, if you have to</b>\n",
        "pad_top =  0#@param {type:\"integer\"}\n",
        "pad_bottom =  10#@param {type:\"integer\"}\n",
        "pad_left =  0#@param {type:\"integer\"}\n",
        "pad_right =  0#@param {type:\"integer\"}\n",
        "rescaleFactor =  1#@param {type:\"integer\"}\n",
        "sr_path = 'checkpoints/esrgan_max.pth' #@param {type:\"string\"}\n",
        "nosmooth = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "loadingAn(name=\"lds\")\n",
        "textAn(\"Analyzing Video...\", ty='twg')\n",
        "\n",
        "if nosmooth == False:\n",
        "  !cd wav2lip-hq && python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --segmentation_path checkpoints/face_segmentation.pth --sr_path checkpoints/esrgan_max.pth --face \"/content/wav2lip-hq/images/image.png\" --audio \"/content/wav2lip-hq/videos/input_audio_imageconverting.wav\" --pads $pad_top $pad_bottom $pad_left $pad_right --resize_factor $rescaleFactor\n",
        "else:\n",
        "  !cd wav2lip-hq && pyt hon inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --segmentation_path checkpoints/face_segmentation.pth --sr_path --face \"/content/wav2lip-hq/images/image.png\" --audio \"/content/wav2lip-hq/videos/input_audio_imageconverting.wav\" --pads $pad_top $pad_bottom $pad_left $pad_right --resize_factor $rescaleFactor --nosmooth\n",
        "\n",
        "#Preview output video\n",
        "clear_output()\n",
        "print(\"Final Video Preview\")\n",
        "print(\"Dowload this video from\", '/content/wav2lip-hq/results/result_voice.mp4')\n",
        "showVideo('/content/wav2lip-hq/results/result_voice.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "U3kdtNrAAJ3_"
      },
      "outputs": [],
      "source": [
        "#@title You might get better results by running this cell\n",
        "pad_top =  0#@param {type:\"integer\"}\n",
        "pad_bottom =  10#@param {type:\"integer\"}\n",
        "pad_left =  0#@param {type:\"integer\"}\n",
        "pad_right =  0#@param {type:\"integer\"}\n",
        "rescaleFactor =  1#@param {type:\"integer\"}\n",
        "\n",
        "loadingAn(name=\"lds\")\n",
        "textAn(\"Analyzing Video...\", ty='twg')\n",
        "\n",
        "!cd wav2lip-hq && python inference.py --checkpoint_path \"checkpoints/wav2lip_gan.pth\"  --segmentation_path \"checkpoints/face_segmentation.pth\"  --sr_path \"checkpoints/esrgan_yunying.pth\" --face \"/content/wav2lip-hq/images/image.png\"  --audio \"/content/wav2lip-hq/videos/input_audio_imageconverting.wav\"  --save_frames  --gt_path \"data/gt\"  --pred_path \"data/lq\"  --no_sr --no_segmentation --pads $pad_top $pad_bottom $pad_left $pad_right --resize_factor $rescaleFactor\n",
        "\n",
        "#Preview output video\n",
        "clear_output()\n",
        "print(\"Final Video Preview\")\n",
        "print(\"Dowload this video from\", '/content/wav2lip-hq/results/result_voice.mp4')\n",
        "showVideo('/content/wav2lip-hq/results/result_voice.mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SI3vexZuAqIg"
      },
      "outputs": [],
      "source": [
        "#@title Download Video\n",
        "#@markdown 1. If it fails try running this cell again.\n",
        "#@markdown 2. Alternatively, you can manually download \"output.mp4\", \"combined.mp4\" from the folder on the left (click \"Refresh\" if missing).\n",
        "\n",
        "print() #see https://github.com/googlecolab/colabtools/issues/468\n",
        "from google.colab import files\n",
        "files.download('/content/wav2lip-hq/results/result_voice.mp4') #fails for Firefox private window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "w5DZntTi1GQA"
      },
      "outputs": [],
      "source": [
        "#@title Delete old result file\n",
        "%rm /content/wav2lip-hq/results/result_voice.mp4\n",
        "from IPython.display import clear_output \n",
        "clear_output()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
